{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hcc7402/Phys503-Work-Campos/blob/main/homework_01_Campos_Chavez.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hDwdVirzvV-q"
      },
      "source": [
        "# Homework 01: Numerical python and data handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "oG_JcysFvV-t"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import subprocess\n",
        "\n",
        "# save check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Ljyqmi6GvV-v"
      },
      "outputs": [],
      "source": [
        "def wget_data(url):\n",
        "    local_path='./tmp_data'\n",
        "    subprocess.run([\"wget\", \"-nc\", \"-P\", local_path, url])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "esMyD2FWvV-w"
      },
      "outputs": [],
      "source": [
        "def locate_data(name, check_exists=True):\n",
        "    local_path='./tmp_data'\n",
        "    path = os.path.join(local_path, name)\n",
        "    if check_exists and not os.path.exists(path):\n",
        "        raise RuxntimeError('No such data file: {}'.format(path))\n",
        "    return path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loee2tWIvV-w"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 1</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr0P3An1vV-w"
      },
      "source": [
        "Use `np.einsum` to evaluate the tensor expression $g^{il} \\Gamma^m_{ki} x^k$ which arises in [contravariant derivatives in General Relativity](https://en.wikipedia.org/wiki/Christoffel_symbols#Covariant_derivatives_of_tensors).  Note we are using the GR convention that repeated indices (k,l) are summed over."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "67ebba3716136199857aaeefd0595675",
          "grade": false,
          "grade_id": "cell-b10c5a1cfe3128da",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "txg7kGyyvV-x"
      },
      "outputs": [],
      "source": [
        "def tensor_expr(g, Gamma, x, D = 4):\n",
        "    \"\"\"Evaluate the tensor expression above.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    g : array\n",
        "        Numpy array of shape (D, D)\n",
        "    Gamma : array\n",
        "        Numpy array of shape (D, D, D)\n",
        "    x : array\n",
        "        Numpy array of shape (D,)\n",
        "    D : int\n",
        "        Dimension of input tensors.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        Numpy array of shape (D, D) that evaluates the tensor expression.\n",
        "    \"\"\"\n",
        "    assert g.shape == (D, D)\n",
        "    assert Gamma.shape == (D, D, D)\n",
        "    assert x.shape == (D,)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    return np.einsum('il,mki,k', g, Gamma, x)   # simple matrix multiplication\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f91f3472db3a535b4aa76494682b0bbd",
          "grade": true,
          "grade_id": "cell-dc1412e0ed9e3c8f",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "5nz4MIVbvV-x"
      },
      "outputs": [],
      "source": [
        "# A correct solution should pass these tests.\n",
        "g = np.arange(4 ** 2).reshape(4, 4)\n",
        "Gamma = np.arange(4 ** 3).reshape(4, 4, 4)\n",
        "x = np.arange(4)\n",
        "y = tensor_expr(g, Gamma, x)\n",
        "assert np.array_equal(\n",
        "    y,\n",
        "    [[ 1680,  3984,  6288,  8592], [ 1940,  4628,  7316, 10004],\n",
        "     [ 2200,  5272,  8344, 11416], [ 2460,  5916,  9372, 12828]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iI4RhThjvV-y"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 2</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgUwFiwSvV-y"
      },
      "source": [
        "Use `np.histogram` to calculate the fraction of values in an arbitrary input data array that lie in each of the 10 intervals \\[0.0, 0.1), \\[0.1, 0.2), ..., \\[0.9, 1.0). You can assume that all input values are in the range \\[0,1). This is a useful technique to estimate the probability density that the data was sampled from."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "0af6aa7170b9f78496e1dbfd925016db",
          "grade": false,
          "grade_id": "cell-366b67031512bdaa",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "1JqwLoQ0vV-z"
      },
      "outputs": [],
      "source": [
        "def estimate_probability_density(data, bins):\n",
        "    \"\"\"Estimate the probability density of arbitrary data.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    data : array\n",
        "        1D numpy array of random values.\n",
        "    bins : array\n",
        "        1D numpy array of N+1 bin edges to use. Must be increasing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    array\n",
        "        1D numpy array of N probability densities.\n",
        "    \"\"\"\n",
        "    assert np.all(np.diff(bins) > 0)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    data = np.array(data)   # turn random geenrated data into array\n",
        "    bins = np.array(bins)   # bins vlaues into array\n",
        "\n",
        "    hist, bin_edges = np.histogram(data, bins=bins)\n",
        "    widths = np.diff(bin_edges)   # width/interval for each bin\n",
        "    N = data.size\n",
        "\n",
        "    rho = hist / (N * widths)   # prob density\n",
        "\n",
        "    return rho\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "f5029940f395172b2bbf68f048632eec",
          "grade": true,
          "grade_id": "cell-3add23f80d497553",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "OVE51VIHvV-z"
      },
      "outputs": [],
      "source": [
        "# A correct solution should pass these tests.\n",
        "generator = np.random.RandomState(seed=123)\n",
        "data = generator.uniform(size=100)\n",
        "bins = np.linspace(0., 1., 11)\n",
        "rho = estimate_probability_density(data, bins)\n",
        "assert np.allclose(0.1 * rho.sum(), 1.)\n",
        "assert np.allclose(rho, [ 0.6,  0.8,  0.7,  1.7,  1.1,  1.3,  1.6,  0.9,  0.8,  0.5])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_fsC8ssvV-z"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 3</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIg9WjXmvV-z"
      },
      "source": [
        "Define a function to calculate the [entropy](https://en.wikipedia.org/wiki/Entropy_estimation) $H(\\rho)$ of a binned probability density, defined as:\n",
        "$$\n",
        "H(\\rho) \\equiv -\\sum_i \\rho_i \\log(\\rho_i) \\Delta w_i \\; ,\n",
        "$$\n",
        "where $\\rho_i$ is the binned density in bin $i$ with width $w_i$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "cdacb2d2924ff83259b567883a4832d0",
          "grade": false,
          "grade_id": "cell-49d830408cabc403",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "kZcQK8TnvV-z"
      },
      "outputs": [],
      "source": [
        "def binned_entropy(rho, bins):\n",
        "    \"\"\"Calculate the binned entropy.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    rho : array\n",
        "        1D numpy array of densities, e.g., calculated by the previous function.\n",
        "    bins : array\n",
        "        1D numpy array of N+1 bin edges to use. Must be increasing.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    float\n",
        "        Value of the binned entropy.\n",
        "    \"\"\"\n",
        "    assert np.all(np.diff(bins) > 0)\n",
        "\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    rho = np.array(rho)   # rho values into array\n",
        "    bins = np.array(bins)   # bins vlaues into array\n",
        "    widths = np.diff(bins)    # width/interval for each bin\n",
        "\n",
        "    H = -1 * np.sum(rho * np.log(rho) * widths)   # calculate entropy\n",
        "\n",
        "    return H\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "2de813a17b08d4d867107f8c4d1b1cee",
          "grade": true,
          "grade_id": "cell-7672bc6e182b3f89",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "b-O0JHVyvV-0"
      },
      "outputs": [],
      "source": [
        "# A correct solution should pass these tests.\n",
        "generator = np.random.RandomState(seed=123)\n",
        "data1 = generator.uniform(size=10000)\n",
        "data2 = generator.uniform(size=10000) ** 4\n",
        "bins = np.linspace(0., 1., 11)\n",
        "rho1 = estimate_probability_density(data1, bins)\n",
        "rho2 = estimate_probability_density(data2, bins)\n",
        "H1 = binned_entropy(rho1, bins)\n",
        "H2 = binned_entropy(rho2, bins)\n",
        "assert np.allclose(H1, -0.000801544)\n",
        "assert np.allclose(H2, -0.699349908)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pRLmFzckvV-0"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 4</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-POUhA8ZvV-0"
      },
      "source": [
        "Define a function that reads `pong_data.hf5` and returns a new subset DataFrame containing only the columns `x5`, `y5`, `x7`, `y7` (**in that order**) and only the last 200 rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fMQIuXQhvV-0"
      },
      "outputs": [],
      "source": [
        "wget_data('https://raw.githubusercontent.com/illinois-ipaml/MachineLearningForPhysics/main/data/pong_data.hf5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "checksum": "0e05585740687be735277fb545caa381",
          "grade": false,
          "grade_id": "cell-0cae4a532ac8ed42",
          "locked": false,
          "schema_version": 1,
          "solution": true
        },
        "id": "n5mnPY5UvV-0"
      },
      "outputs": [],
      "source": [
        "def create_subset():\n",
        "    \"\"\"Read pong_data.hf5 and return a subset.\n",
        "    \"\"\"\n",
        "    # YOUR CODE HERE\n",
        "\n",
        "    pong_data = pd.read_hdf(locate_data('pong_data.hf5'))   # read pong data\n",
        "    df = pd.DataFrame(pong_data)    # create dataframe\n",
        "\n",
        "    pong_data_subset_df = df[['x5', 'y5', 'x7', 'y7']]    # create subset with specified columns\n",
        "    pong_data_subset_df = pong_data_subset_df.tail(200)   # create further subset with last 200 rows\n",
        "\n",
        "    return pong_data_subset_df\n",
        "\n",
        "    raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "checksum": "38f3af71e1904885fe03f432dd55f281",
          "grade": true,
          "grade_id": "cell-30143518143c64b1",
          "locked": true,
          "points": 1,
          "schema_version": 1,
          "solution": false
        },
        "id": "8eiSH047vV-1"
      },
      "outputs": [],
      "source": [
        "# A correct solution should pass these tests.\n",
        "subset = create_subset()\n",
        "assert np.array_equal(subset.columns.values, ('x5', 'y5', 'x7', 'y7'))\n",
        "assert len(subset) == 200\n",
        "summary = subset.describe()\n",
        "assert np.allclose(summary.loc['mean', :].values,\n",
        "                   [ 0.43564752,  0.30610958,  0.57520991,  0.21383226])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wV7mcqJOvV-1"
      },
      "source": [
        "## <span style=\"color:Orange\">Acknowledgments</span>\n",
        "\n",
        "* Initial version: Mark Neubauer\n",
        "\n",
        "Â© Copyright 2025"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": [],
      "name": "homework_01_Campos_Chavez.ipynb",
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}