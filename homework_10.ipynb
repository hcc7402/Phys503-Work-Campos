{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hcc7402/Phys503-Work-Campos/blob/week11/homework_10.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "15b8a5c7",
      "metadata": {
        "id": "15b8a5c7"
      },
      "source": [
        "# Homework 10: Forecasting Projectile Motion with Recurrent Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a-utiRozzioB",
      "metadata": {
        "id": "a-utiRozzioB"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set_theme()\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Use CPU rather than GPU for keras neural networks\n",
        "import os\n",
        "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
        "from tensorflow import keras\n",
        "from tqdm.keras import TqdmCallback"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c6b9ef",
      "metadata": {
        "id": "45c6b9ef"
      },
      "source": [
        "## <span style=\"color:LightGreen\">Projectile data used in this homework</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3c77299b",
      "metadata": {
        "id": "3c77299b"
      },
      "source": [
        "Simulations of the motion of several trapezoid shaped projectiles after having been catapulted from the ground were performed using [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/01_Simulating_Projectile_Motion_with_Drag.ipynb) from the APS Group on Data Science. This is an imagined scenario but takes the simple Newtonian motion of an idealized projectile and considers a more realistic scenario of varied drag.\n",
        "\n",
        "This data includes a varied drag coefficient and projectile area for four sides of the object.\n",
        "\n",
        "A large number of these runs was simulated and saved in the file `launches.csv`. We begin by loading this file of simulated launches.\n",
        "\n",
        "In [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/02_Time_Series_Analysis_and_Forecasting.ipynb), some classical time series analysis techniques to better understand that data and then demonstrated linear techniques for \"forecasting\" or predicting the future state of the projectile, given some initial portion of the data.\n",
        "\n",
        "In this notebook, we will explore the use of <span style=\"color:Violet\">neural networks</span>, which as you know are nonlinear models, to forecast future states of the projectile, given the previous locations and other information. For example, if we know how the projectile travelled from time $t=0$ to time $t=10$, where will it be at time $t=11$?\n",
        "\n",
        "Although you can calculate this with Newton's second law, the previously referenced [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/02_Time_Series_Analysis_and_Forecasting.ipynb) demonstrated that this calculation can be more tricky if you do not know the exact drag coefficient on the projectile.\n",
        "\n",
        "We begin by loading the file of simulated launches, which will be our data for tuning and testing the neural network parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tHXdTJ4vD3zk",
      "metadata": {
        "id": "tHXdTJ4vD3zk"
      },
      "outputs": [],
      "source": [
        "# Load our launch data\n",
        "data_location = \"https://raw.githubusercontent.com/GDS-Education-Community-of-Practice/DSECOP/main/Time_Series_Analysis_and_Forecasting/launches.csv\"\n",
        "all_launches = pd.read_csv(data_location, index_col=\"Time (s)\")\n",
        "\n",
        "# Split into individual launches\n",
        "split_indices = np.where(all_launches.index[1:] - all_launches.index[0:-1] < 0)[0].tolist() # Find where time decreases (signifies different launch)\n",
        "split_indices = [0] + split_indices + [all_launches.shape[0]]\n",
        "launches = [all_launches.iloc[split_indices[i]+1:split_indices[i+1]] for i in range(100)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tulo_2LFjKWQ",
      "metadata": {
        "id": "tulo_2LFjKWQ"
      },
      "source": [
        "We can examine what these 100 launches look like"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KqvfcaKojrug",
      "metadata": {
        "id": "KqvfcaKojrug"
      },
      "outputs": [],
      "source": [
        "print(\"Number of launches: {}\".format(len(launches)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qJdLdG9FjNdJ",
      "metadata": {
        "id": "qJdLdG9FjNdJ"
      },
      "outputs": [],
      "source": [
        "all_launches.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "WHr7rSAKjlMT",
      "metadata": {
        "id": "WHr7rSAKjlMT"
      },
      "source": [
        "As you can see, the launch data comprises of 100 launches which are made up of time points every 0.1 seconds and variables of distance, height, drag coefficient, and projectile area over these times.\n",
        "\n",
        "In this notebook, we will mostly use a single test case (launch 20, for no special reason).\n",
        "However, at the end of the notebook, all the launches will be used to train the recurrent neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51a83df7",
      "metadata": {
        "id": "51a83df7"
      },
      "source": [
        "## <span style=\"color:LightGreen\">Forecasting projectile data with recurrent neural networks</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rDahbG3eqkbs",
      "metadata": {
        "id": "rDahbG3eqkbs"
      },
      "source": [
        "<hr/>\n",
        "\n",
        "*Note:* Recurrent neural networks are often large and nonlinear and thus very complex models.\n",
        "On the one hand, this means that they are capable of capturing complicated relationships and patterns.\n",
        "On the other hand, this means that they often require a lot of challenging \"data engineering\" (getting data in the right form to force the model to see what you want it to) and parameter tuning.\n",
        "For the remainder of this notebook, you will experience some of these challenges firsthand.\n",
        "There are alternative methods for overcoming them than are presented, but know that the experience you will be having is the same as for those who use these models professionally in business and scientific applications.\n",
        "\n",
        "<hr/>\n",
        "\n",
        "Recurrent neural networks are mainly used for sequential information because of their repetitive nature.\n",
        "This is perfectly suited for time series data such as our projectile data.\n",
        "\n",
        "Similarly to the application of the [Autoregressive moving-average](https://en.wikipedia.org/wiki/Autoregressive_moving-average_model) (ARMA) linear model in previously referenced [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/02_Time_Series_Analysis_and_Forecasting.ipynb), we will consider our test launch as our training data.\n",
        "As we did in the example, we will consider taking two steps of the distance variable and try to predict the next distance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "WU8ttzxu8p6I",
      "metadata": {
        "id": "WU8ttzxu8p6I"
      },
      "outputs": [],
      "source": [
        "# Get our test launch data\n",
        "test_launch = launches[20]\n",
        "\n",
        "# Take the first quarter of the data\n",
        "distance = test_launch[\"Distance (m)\"]\n",
        "quarter_distance = np.array(distance.iloc[1:17])\n",
        "quarter_height = np.array(test_launch[\"Height (m)\"].iloc[1:17])\n",
        "\n",
        "# Organize the data for our recurrent neural network\n",
        "k = 2\n",
        "distance_in = []\n",
        "distance_out = []\n",
        "for i in range(len(quarter_distance)-k):\n",
        "  # Take k samples at time t_i ... t_{i+k-1}\n",
        "  distance_in.append(quarter_distance[i:i+k].reshape((k,1)))\n",
        "  # Get function output at time t_{i+k}\n",
        "  distance_out.append(quarter_distance[i+k])\n",
        "\n",
        "distance_in = np.array(distance_in)\n",
        "distance_out = np.array(distance_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hAth-ag0_Jht",
      "metadata": {
        "id": "hAth-ag0_Jht"
      },
      "outputs": [],
      "source": [
        "keras.utils.set_random_seed(0)\n",
        "\n",
        "# Make simple many to one model (input 2 samples of size 1)\n",
        "x = keras.layers.Input(shape=(k,1))\n",
        "y = keras.layers.SimpleRNN(10,activation=\"tanh\", return_sequences=True)(x)\n",
        "y = keras.layers.SimpleRNN(1,activation=\"linear\", return_sequences=False)(y)\n",
        "distance_model  = keras.Model(inputs=x,outputs=y)\n",
        "\n",
        "# Train model\n",
        "distance_model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = keras.losses.MeanSquaredError()\n",
        ")\n",
        "history = distance_model.fit(\n",
        "    distance_in,\n",
        "    distance_out,\n",
        "    batch_size=10,         # The training takes groups of samples (in this case 10 samples at a time)\n",
        "    epochs=2000,           # The number of times to iterate through our dataset\n",
        "    validation_split = 0 , # Use 0% of data to check accuracy\n",
        "    verbose=0,             # Don't print info as it trains\n",
        "    callbacks=[TqdmCallback(verbose=0)]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lJvfoPdpgRhU",
      "metadata": {
        "id": "lJvfoPdpgRhU"
      },
      "outputs": [],
      "source": [
        "# Plot prediction and the true values\n",
        "data_distance = distance.iloc[17:]\n",
        "data_height = test_launch[\"Height (m)\"].iloc[17:]\n",
        "\n",
        "# Run predictions through the model to get the next time step\n",
        "predictions = [distance_in[-1][i,0] for i in range(k)]\n",
        "for i in range(len(data_distance)):\n",
        "  # Get the k previous steps\n",
        "  i_input = np.array([predictions[-i] for i in range(k,0,-1)])\n",
        "  prediction = distance_model(i_input.reshape((1,k,1)))\n",
        "  # Convert single value matrix to just a number\n",
        "  predictions.append(np.array(prediction)[0][0])\n",
        "\n",
        "# Cut out first k predictions (that we actually already knew)\n",
        "predictions = np.array(predictions[k:])\n",
        "\n",
        "# Plot\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(quarter_distance, quarter_height, label=\"Input\")\n",
        "plt.scatter(data_distance, data_height, label=\"True data\")\n",
        "plt.scatter(predictions, data_height, label=\"Predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "28SZyNgZKsbP",
      "metadata": {
        "id": "28SZyNgZKsbP"
      },
      "source": [
        "Well, those predictions are no good!\n",
        "Apparently, our model is unable to predict the next portion of the data..\n",
        "This is because the model is not good at \"extrapolation\" or predicting beyond where it was trained (this is more common for nonlinear models like our recurrent neural network than for linear models like ARMA because they are more flexible).\n",
        "Note that all of the input data is in the range 0 to 75.\n",
        "It seems that as soon as we give data beyond that, the model spits out values that it has seen before.\n",
        "\n",
        "One way to avoid this issue would be to first make our data stationary or close to stationary (see the previously referenced [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/02_Time_Series_Analysis_and_Forecasting.ipynb) for more information).\n",
        "We can do this by subtracting the data at the previous time from the current data.\n",
        "Our new stationary distance will then be in the range of the training data and work better with our network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "oqyivZMgn4b3",
      "metadata": {
        "id": "oqyivZMgn4b3"
      },
      "outputs": [],
      "source": [
        "keras.utils.set_random_seed(0)\n",
        "\n",
        "# Take the first quarter of the data (stationary)\n",
        "original_distance = test_launch[\"Distance (m)\"].shift()\n",
        "distance = test_launch[\"Distance (m)\"] - test_launch[\"Distance (m)\"].shift()\n",
        "quarter_distance = np.array(distance.iloc[1:17])\n",
        "quarter_height = np.array(test_launch[\"Height (m)\"].iloc[1:17])\n",
        "\n",
        "# Organize the data for our recurrent neural network\n",
        "k = 2\n",
        "distance_in = []\n",
        "distance_out = []\n",
        "for i in range(len(quarter_distance)-k):\n",
        "  # Take k samples at time t_i ... t_{i+k-1}\n",
        "  distance_in.append(quarter_distance[i:i+k].reshape((k,1)))\n",
        "  # Get function output at time t_{i+k}\n",
        "  distance_out.append(quarter_distance[i+k])\n",
        "\n",
        "distance_in = np.array(distance_in)\n",
        "distance_out = np.array(distance_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g8S38ouin8sP",
      "metadata": {
        "id": "g8S38ouin8sP"
      },
      "source": [
        "Now, we can make a new model and train it with this new stationary data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0Fjggy9roO02",
      "metadata": {
        "id": "0Fjggy9roO02"
      },
      "outputs": [],
      "source": [
        "# Make simple many to one model (input 2 samples of size 1)\n",
        "x = keras.layers.Input(shape=(k,1))\n",
        "y = keras.layers.SimpleRNN(10,activation=\"tanh\", return_sequences=True)(x)\n",
        "y = keras.layers.SimpleRNN(1,activation=\"linear\", return_sequences=False)(y)\n",
        "distance_model  = keras.Model(inputs=x,outputs=y)\n",
        "\n",
        "# Train model\n",
        "distance_model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = keras.losses.MeanSquaredError()\n",
        ")\n",
        "history = distance_model.fit(\n",
        "    distance_in,\n",
        "    distance_out,\n",
        "    batch_size=10,         # The training takes groups of samples (in this case 10 samples at a time)\n",
        "    epochs=2000,           # The number of times to iterate through our dataset\n",
        "    validation_split = 0,  # Use 0% of data to check accuracy\n",
        "    verbose=0,             # Don't print info as it trains\n",
        "    callbacks=[TqdmCallback(verbose=0)]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8Tnt15S7oQLA",
      "metadata": {
        "id": "8Tnt15S7oQLA"
      },
      "source": [
        "And now we can make and plot the predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "A6QZaATvhfwO",
      "metadata": {
        "id": "A6QZaATvhfwO"
      },
      "outputs": [],
      "source": [
        "# Plot prediction and the true values\n",
        "data_distance = distance.iloc[17:]\n",
        "data_height = test_launch[\"Height (m)\"].iloc[17:]\n",
        "\n",
        "# Run predictions through the model to get the next time step\n",
        "predictions = [distance_in[-1][i,0] for i in range(k)]\n",
        "for i in range(len(data_distance)):\n",
        "  # Get the k previous steps\n",
        "  i_input = np.array([predictions[-i] for i in range(k,0,-1)])\n",
        "  prediction = distance_model(i_input.reshape((1,k,1)))\n",
        "  # Convert single value matrix to just a number\n",
        "  predictions.append(np.array(prediction)[0][0])\n",
        "\n",
        "# Cut out first k predictions (that we actually already knew)\n",
        "predictions = np.array(predictions[k:])\n",
        "\n",
        "# Shift data and predictions\n",
        "shift_quarter_distance = quarter_distance+original_distance.iloc[1:17]\n",
        "shift_data_distance = data_distance+original_distance.iloc[17:]\n",
        "shift_predictions = [predictions[0]+original_distance.iloc[17]]\n",
        "for pred in predictions[1:]:\n",
        "  shift_predictions.append(pred + shift_predictions[-1])\n",
        "\n",
        "# Plot\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(shift_quarter_distance, quarter_height, label=\"Input\")\n",
        "plt.scatter(shift_data_distance, data_height, label=\"True data\")\n",
        "plt.scatter(shift_predictions, data_height, label=\"Predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wHq3bfugh_GX",
      "metadata": {
        "id": "wHq3bfugh_GX"
      },
      "source": [
        "Well that worked enormously better!\n",
        "But the results still look somewhat equivalent to the linear models of ARMA in the previously referenced [notebook](https://github.com/GDS-Education-Community-of-Practice/DSECOP/blob/main/Time_Series_Analysis_and_Forecasting/02_Time_Series_Analysis_and_Forecasting.ipynb).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74d6db08",
      "metadata": {
        "id": "74d6db08"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 1</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8gUF2wOOL8Nv",
      "metadata": {
        "id": "8gUF2wOOL8Nv"
      },
      "source": [
        "Try adding more `SimpleRNN` layers, changing the number of nodes in the layers, adding more training `epochs`, and adjusting the number of time points `k` for the dataset to acheive more accurate results. Remake the last plot above with this better tuned hyperparameters.\n",
        "\n",
        "How close can you get to a good prediction of the projectile data?\n",
        "\n",
        "*Note:* It is recommended that you change one at a time to see how each component affects the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fHtN-LhXKxmg",
      "metadata": {
        "id": "fHtN-LhXKxmg"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "nrx3lZw-i0Ek",
      "metadata": {
        "id": "nrx3lZw-i0Ek"
      },
      "source": [
        "----\n",
        "\n",
        "Now, up until now, our data has been entirely based on the distance information.\n",
        "However, our dataset contains more than just distance.\n",
        "Also, notably, classical linear models such as ARMA cannot easily incorporate more than one variable.\n",
        "But neural networks are very well suited to high dimensional data.\n",
        "\n",
        "What if we also include the height variable in the training and prediction?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "hy0_9LS8xTEG",
      "metadata": {
        "id": "hy0_9LS8xTEG"
      },
      "outputs": [],
      "source": [
        "keras.utils.set_random_seed(0)\n",
        "\n",
        "# Take the first quarter of the data (stationary)\n",
        "original_dh = test_launch[[\"Distance (m)\", \"Height (m)\"]].shift()\n",
        "dh_data = test_launch[[\"Distance (m)\", \"Height (m)\"]] - test_launch[[\"Distance (m)\", \"Height (m)\"]].shift()\n",
        "quarter_dh = np.array(dh_data.iloc[1:17])\n",
        "quarter_height = np.array(test_launch[\"Height (m)\"].iloc[1:17])\n",
        "\n",
        "# Organize the data for our recurrent neural network\n",
        "k = 4\n",
        "dh_in = []\n",
        "distance_out = []\n",
        "for i in range(len(quarter_dh)-k):\n",
        "  # Take k samples at time t_i ... t_{i+k-1}\n",
        "  dh_in.append(quarter_dh[i:i+k])\n",
        "  # Get function output at time t_{i+k}\n",
        "  distance_out.append(quarter_dh[i+k,0])\n",
        "\n",
        "dh_in = np.array(dh_in)\n",
        "distance_out = np.array(distance_out)\n",
        "\n",
        "# Make simple many to one model (input 2 samples of size 2 variables)\n",
        "x = keras.layers.Input(shape=(k,2))\n",
        "y = keras.layers.SimpleRNN(10,activation=\"tanh\", return_sequences=True)(x)\n",
        "y = keras.layers.SimpleRNN(1,activation=\"linear\", return_sequences=False)(y)\n",
        "dh_model  = keras.Model(inputs=x,outputs=y)\n",
        "\n",
        "# Train model\n",
        "dh_model.compile(\n",
        "    optimizer = keras.optimizers.Adam(),\n",
        "    loss = keras.losses.MeanSquaredError()\n",
        ")\n",
        "history = dh_model.fit(\n",
        "    dh_in,\n",
        "    distance_out,\n",
        "    batch_size=10,         # The training takes groups of samples (in this case 10 samples at a time)\n",
        "    epochs=2000,           # The number of times to iterate through our dataset\n",
        "    validation_split = 0,  # Use 0% of data to check accuracy\n",
        "    verbose=0,             # Don't print info as it trains\n",
        "    callbacks=[TqdmCallback(verbose=0)]\n",
        ")\n",
        "\n",
        "# Plot prediction and the true values\n",
        "data_distance = test_launch[\"Distance (m)\"].iloc[17:]\n",
        "data_height = test_launch[\"Height (m)\"].iloc[17:]\n",
        "\n",
        "# Run predictions through the model to get the next time step\n",
        "predictions = [dh_in[-1][i,0] for i in range(k)]\n",
        "for i in range(len(data_distance)):\n",
        "  # Get the k previous steps of height and with predicted distance\n",
        "  i_input = np.vstack([\n",
        "      np.array([predictions[-i] for i in range(k,0,-1)]),\n",
        "      np.array([dh_data[\"Height (m)\"].iloc[17+i-j] for j in range(k,0,-1)])\n",
        "  ]).T\n",
        "  prediction = dh_model(i_input.reshape((1,k,2)))\n",
        "  # Convert single value matrix to just a number\n",
        "  predictions.append(np.array(prediction)[0][0])\n",
        "\n",
        "# Cut out first k predictions (that we actually already knew)\n",
        "predictions = np.array(predictions[k:])\n",
        "\n",
        "# Shift data and predictions\n",
        "shift_quarter_distance = quarter_dh[:,0]+original_dh[\"Distance (m)\"].iloc[1:17]\n",
        "shift_data_distance = data_distance\n",
        "shift_predictions = [predictions[0]+original_dh[\"Distance (m)\"].iloc[17]]\n",
        "for pred in predictions[1:]:\n",
        "  shift_predictions.append(pred + shift_predictions[-1])\n",
        "\n",
        "# Plot\n",
        "plt.close('all')\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.scatter(shift_quarter_distance, quarter_height, label=\"Input\")\n",
        "plt.scatter(shift_data_distance, data_height, label=\"True data\")\n",
        "plt.scatter(shift_predictions, data_height, label=\"Predicted data\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mUsDPw5TP198",
      "metadata": {
        "id": "mUsDPw5TP198"
      },
      "source": [
        "This result doesn't look too different from our previous result, but notice that we needed to change to use `k=4` previous time points to make the prediction.\n",
        "\n",
        "You can try to use `k=2` to see the interesting predictions that it yields (because the height values repeat themselves when the projectile comes back down, the predictions show distance decreasing!).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "114cbe12",
      "metadata": {
        "id": "114cbe12"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 2</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "HT4wowHvQQGR",
      "metadata": {
        "id": "HT4wowHvQQGR"
      },
      "source": [
        "Using the example above, include the other variables in our dataset.\n",
        "Namely, include the drag coefficient and projectile area.\n",
        "\n",
        "Do these help with the prediction accuracy (without changing anything else)?\n",
        "Why or why not might that be?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HRAMCgXMQduC",
      "metadata": {
        "id": "HRAMCgXMQduC"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1nReL3axRmzW",
      "metadata": {
        "id": "1nReL3axRmzW"
      },
      "source": [
        "Including the drag and area doesn't seem to help with the prediction at all.\n",
        "This may be because the drag and area both assist in determining the jump in the distance between time points, which is already captured fairly well by the previous distance points.\n",
        "In other words, the drag and area are almost redundant information given the previous distance samples.\n",
        "\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f9703824",
      "metadata": {
        "id": "f9703824"
      },
      "source": [
        "## <span style=\"color:Orange\">Problem 3</span>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "L70ALlLJSNK9",
      "metadata": {
        "id": "L70ALlLJSNK9"
      },
      "source": [
        "So far, we have only used a single test launch.\n",
        "However, the network training can be improved by incorporating all of the launches.\n",
        "In fact, all of the launches can be used in their entirety to train the network, after which we can test it on the case we have been considering.\n",
        "\n",
        "In this problem, fit (or train) the network on all of the data contained in `launches` except for the 20th entry (which is `test_launch`), then predict on the last 3/4 of the data from `test_launch` as the previous examples and problems have shown (which envisions only seeing the first part of the trajectory and needing to know the rest).\n",
        "The notebook cell for organizing the stationary data earlier in the notebook is a good starting point for what to change to add all the launches in.\n",
        "\n",
        "*Note:* You will likely need to decrease the number of `epochs` due to the much larger dataset.\n",
        "Also, use `np.any(np.isnan())` to make sure you don't add anything with `NaN` (not a number) to the dataset.\n",
        "\n",
        "*Help:* To work with the `all_launches` Pandas dataset, [this cheatsheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf) may be helpful."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Zg31nnG6R-eO",
      "metadata": {
        "id": "Zg31nnG6R-eO"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE\n",
        "raise NotImplementedError()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XEc3Qkn5kLY7",
      "metadata": {
        "id": "XEc3Qkn5kLY7"
      },
      "source": [
        "The prediction with your RNN should be spot on!"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "wGJg7hk3zuws",
      "metadata": {
        "id": "wGJg7hk3zuws"
      },
      "source": [
        "## <span style=\"color:Orange\">Appendix</span>\n",
        "\n",
        "### <span style=\"color:LightGreen\">Additional Information</span>\n",
        "\n",
        "There are many drawbacks with the recurrent neural network architecture as presented in this notebook (such as training difficulties with vanishing gradients or lack of generalizability).\n",
        "More complicated but improved alternatives that could be used as replacements for the `SimpleRNN` layer used in this notebook are:\n",
        "\n",
        "- [`LSTM`](https://keras.io/api/layers/recurrent_layers/lstm/) which is described [here](https://en.wikipedia.org/wiki/Long_short-term_memory)\n",
        "-[`GRU`](https://keras.io/api/layers/recurrent_layers/gru/) which is described [here](https://en.wikipedia.org/wiki/Gated_recurrent_unit)\n",
        "\n",
        "### <span style=\"color:LightGreen\">Resources</span>\n",
        "\n",
        "- https://towardsdatascience.com/time-series-forecasting-deep-learning-vs-statistics-who-wins-c568389d02df\n",
        "- https://neptune.ai/blog/time-series-prediction-vs-machine-learning"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "512ba1cf",
      "metadata": {
        "id": "512ba1cf"
      },
      "source": [
        "## <span style=\"color:Orange\">Acknowledgments</span>\n",
        "\n",
        "* Initial version: Mark Neubauer\n",
        "  * From APS GDS repository\n",
        "\n",
        "Â© Copyright 2025"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}